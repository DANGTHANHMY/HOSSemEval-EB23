{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ac35ac",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-24T05:02:25.949155Z",
     "iopub.status.busy": "2024-10-24T05:02:25.948817Z",
     "iopub.status.idle": "2024-10-24T05:02:34.271882Z",
     "shell.execute_reply": "2024-10-24T05:02:34.270931Z"
    },
    "papermill": {
     "duration": 8.332646,
     "end_time": "2024-10-24T05:02:34.274251",
     "exception": false,
     "start_time": "2024-10-24T05:02:25.941605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'HOSSemEval-EB23'...\r\n",
      "remote: Enumerating objects: 318, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (128/128), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (84/84), done.\u001b[K\r\n",
      "remote: Total 318 (delta 74), reused 78 (delta 41), pack-reused 190 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (318/318), 33.43 MiB | 15.07 MiB/s, done.\r\n",
      "Resolving deltas: 100% (167/167), done.\r\n",
      "Updating files: 100% (136/136), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/DANGTHANHMY/HOSSemEval-EB23.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72935fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:02:34.296167Z",
     "iopub.status.busy": "2024-10-24T05:02:34.295821Z",
     "iopub.status.idle": "2024-10-24T05:02:35.302836Z",
     "shell.execute_reply": "2024-10-24T05:02:35.301727Z"
    },
    "papermill": {
     "duration": 1.02076,
     "end_time": "2024-10-24T05:02:35.305375",
     "exception": false,
     "start_time": "2024-10-24T05:02:34.284615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOSSemEval-EB23  __notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b9c9a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:02:35.326782Z",
     "iopub.status.busy": "2024-10-24T05:02:35.326443Z",
     "iopub.status.idle": "2024-10-24T05:05:22.134139Z",
     "shell.execute_reply": "2024-10-24T05:05:22.133021Z"
    },
    "papermill": {
     "duration": 166.820968,
     "end_time": "2024-10-24T05:05:22.136533",
     "exception": false,
     "start_time": "2024-10-24T05:02:35.315565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 1)) (24.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 2)) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 3)) (1.14.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 4)) (3.7.5)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 5)) (2.2.2)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 6)) (1.2.2)\r\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 7)) (0.12.2)\r\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (2.16.1)\r\n",
      "Collecting typing-extensions==4.6.2 (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 9))\r\n",
      "  Downloading typing_extensions-4.6.2-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting sentencepiece==0.1.99 (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 10))\r\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n",
      "Collecting pytorch_lightning==1.9.5 (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\r\n",
      "Collecting tqdm==4.65.0 (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 12))\r\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting transformers==4.16.0 (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 13))\r\n",
      "  Downloading transformers-4.16.0-py3-none-any.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting openai==0.27.7 (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 14))\r\n",
      "  Downloading openai-0.27.7-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting Requests==2.31.0 (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 15))\r\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting sentence-transformers (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 16))\r\n",
      "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: easydict in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 17)) (1.13)\r\n",
      "Collecting editdistance (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 18))\r\n",
      "  Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11)) (2.4.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11)) (6.0.2)\r\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11)) (2024.6.1)\r\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11)) (1.4.1)\r\n",
      "Requirement already satisfied: packaging>=17.1 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11)) (21.3)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /opt/conda/lib/python3.10/site-packages (from pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11)) (0.11.6)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.0->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 13)) (3.15.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.0->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 13)) (0.24.6)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.0->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 13)) (2024.5.15)\r\n",
      "Collecting sacremoses (from transformers==4.16.0->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 13))\r\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.0->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 13)) (0.19.1)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai==0.27.7->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 14)) (3.9.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from Requests==2.31.0->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 15)) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from Requests==2.31.0->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 15)) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from Requests==2.31.0->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 15)) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from Requests==2.31.0->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 15)) (2024.7.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 4)) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 4)) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 4)) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 4)) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 4)) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 4)) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 4)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 5)) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 5)) (2024.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 6)) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 6)) (3.5.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (0.3.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (3.3.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (70.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (2.4.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (1.62.2)\r\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (2.16.2)\r\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (3.3.3)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (0.37.0)\r\n",
      "INFO: pip is looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting sentence-transformers (from -r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 16))\r\n",
      "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "  Downloading sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\r\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "  Downloading sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "INFO: pip is still looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\r\n",
      "  Downloading sentence_transformers-2.6.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "  Downloading sentence_transformers-2.5.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "  Downloading sentence_transformers-2.4.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "  Downloading sentence_transformers-2.3.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n",
      "  Downloading sentence_transformers-2.3.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 16)) (0.19.0)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 16)) (3.2.4)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (0.43.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.27.7->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 14)) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.27.7->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 14)) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.27.7->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 14)) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.27.7->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 14)) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.27.7->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 14)) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.27.7->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 14)) (4.0.3)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (0.11.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (3.0.3)\r\n",
      "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting torch>=1.10.0 (from pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\r\n",
      "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\r\n",
      "INFO: pip is still looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\r\n",
      "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11)) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11)) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11)) (3.1.4)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.1.0 (from torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11))\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->transformers==4.16.0->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 13)) (8.1.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (2.1.5)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (2.18.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->pytorch_lightning==1.9.5->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 11)) (1.3.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow->-r /kaggle/working/HOSSemEval-EB23/requirements.txt (line 8)) (0.1.2)\r\n",
      "Downloading typing_extensions-4.6.2-py3-none-any.whl (31 kB)\r\n",
      "Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.65.0-py3-none-any.whl (77 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading transformers-4.16.0-py3-none-any.whl (3.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading openai-0.27.7-py3-none-any.whl (71 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m522.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\r\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=c8751c1382715e5684254211ecdb0178f1e629a2bbae750584bb3e50e48a6228\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\r\n",
      "Successfully built sentence-transformers\r\n",
      "Installing collected packages: sentencepiece, typing-extensions, triton, tqdm, Requests, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, editdistance, sacremoses, nvidia-cusparse-cu12, nvidia-cudnn-cu12, openai, nvidia-cusolver-cu12, transformers, torch, sentence-transformers, pytorch_lightning\r\n",
      "  Attempting uninstall: sentencepiece\r\n",
      "    Found existing installation: sentencepiece 0.2.0\r\n",
      "    Uninstalling sentencepiece-0.2.0:\r\n",
      "      Successfully uninstalled sentencepiece-0.2.0\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.12.2\r\n",
      "    Uninstalling typing_extensions-4.12.2:\r\n",
      "      Successfully uninstalled typing_extensions-4.12.2\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.4\r\n",
      "    Uninstalling tqdm-4.66.4:\r\n",
      "      Successfully uninstalled tqdm-4.66.4\r\n",
      "  Attempting uninstall: Requests\r\n",
      "    Found existing installation: requests 2.32.3\r\n",
      "    Uninstalling requests-2.32.3:\r\n",
      "      Successfully uninstalled requests-2.32.3\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.44.0\r\n",
      "    Uninstalling transformers-4.44.0:\r\n",
      "      Successfully uninstalled transformers-4.44.0\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.4.0\r\n",
      "    Uninstalling torch-2.4.0:\r\n",
      "      Successfully uninstalled torch-2.4.0\r\n",
      "  Attempting uninstall: pytorch_lightning\r\n",
      "    Found existing installation: pytorch-lightning 2.4.0\r\n",
      "    Uninstalling pytorch-lightning-2.4.0:\r\n",
      "      Successfully uninstalled pytorch-lightning-2.4.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 24.8.2 requires cubinlinker, which is not installed.\r\n",
      "cudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 24.8.2 requires ptxcompiler, which is not installed.\r\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "albucore 0.0.13 requires typing-extensions>=4.9.0, but you have typing-extensions 4.6.2 which is incompatible.\r\n",
      "albumentations 1.4.14 requires typing-extensions>=4.9.0, but you have typing-extensions 4.6.2 which is incompatible.\r\n",
      "altair 5.4.0 requires typing-extensions>=4.10.0; python_version < \"3.13\", but you have typing-extensions 4.6.2 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\r\n",
      "conda 24.7.1 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\r\n",
      "cudf 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\r\n",
      "datasets 2.21.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\r\n",
      "datasets 2.21.0 requires tqdm>=4.66.3, but you have tqdm 4.65.0 which is incompatible.\r\n",
      "emoji 2.12.1 requires typing-extensions>=4.7.0, but you have typing-extensions 4.6.2 which is incompatible.\r\n",
      "fastapi 0.111.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.6.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.65.0 which is incompatible.\r\n",
      "fitter 1.7.1 requires tqdm<5.0.0,>=4.65.1, but you have tqdm 4.65.0 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "jupyterlab 4.2.4 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "kaggle-environments 1.14.15 requires transformers>=4.33.1, but you have transformers 4.16.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.4 requires shapely<2.1,>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "typeguard 4.3.0 requires typing-extensions>=4.10.0, but you have typing-extensions 4.6.2 which is incompatible.\r\n",
      "ydata-profiling 4.9.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed Requests-2.31.0 editdistance-0.8.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 openai-0.27.7 pytorch_lightning-1.9.5 sacremoses-0.1.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 torch-2.1.2 tqdm-4.65.0 transformers-4.16.0 triton-2.1.0 typing-extensions-4.6.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r \"/kaggle/working/HOSSemEval-EB23/requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab411aa",
   "metadata": {
    "papermill": {
     "duration": 0.083112,
     "end_time": "2024-10-24T05:05:22.304871",
     "exception": false,
     "start_time": "2024-10-24T05:05:22.221759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **TAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e03922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:22.475141Z",
     "iopub.status.busy": "2024-10-24T05:05:22.474460Z",
     "iopub.status.idle": "2024-10-24T05:05:22.478916Z",
     "shell.execute_reply": "2024-10-24T05:05:22.478078Z"
    },
    "papermill": {
     "duration": 0.091405,
     "end_time": "2024-10-24T05:05:22.480795",
     "exception": false,
     "start_time": "2024-10-24T05:05:22.389390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/HOSSemEval-EB23/TAS/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117ed8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:22.647684Z",
     "iopub.status.busy": "2024-10-24T05:05:22.647375Z",
     "iopub.status.idle": "2024-10-24T05:05:22.651293Z",
     "shell.execute_reply": "2024-10-24T05:05:22.650497Z"
    },
    "papermill": {
     "duration": 0.089553,
     "end_time": "2024-10-24T05:05:22.653157",
     "exception": false,
     "start_time": "2024-10-24T05:05:22.563604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python data_preprocessing_for_TAS.py --dataset VNModels_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa04b84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:22.821569Z",
     "iopub.status.busy": "2024-10-24T05:05:22.821272Z",
     "iopub.status.idle": "2024-10-24T05:05:22.824985Z",
     "shell.execute_reply": "2024-10-24T05:05:22.824214Z"
    },
    "papermill": {
     "duration": 0.088806,
     "end_time": "2024-10-24T05:05:22.826833",
     "exception": false,
     "start_time": "2024-10-24T05:05:22.738027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/HOSSemEval-EB23/TAS/TAS-Transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311b7e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:23.032487Z",
     "iopub.status.busy": "2024-10-24T05:05:23.032112Z",
     "iopub.status.idle": "2024-10-24T05:05:23.036005Z",
     "shell.execute_reply": "2024-10-24T05:05:23.035199Z"
    },
    "papermill": {
     "duration": 0.128229,
     "end_time": "2024-10-24T05:05:23.037892",
     "exception": false,
     "start_time": "2024-10-24T05:05:22.909663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3fcc8a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:23.205311Z",
     "iopub.status.busy": "2024-10-24T05:05:23.204976Z",
     "iopub.status.idle": "2024-10-24T05:05:23.208723Z",
     "shell.execute_reply": "2024-10-24T05:05:23.207938Z"
    },
    "papermill": {
     "duration": 0.090007,
     "end_time": "2024-10-24T05:05:23.210779",
     "exception": false,
     "start_time": "2024-10-24T05:05:23.120772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vinai/phobert-base-v2\n",
    "# avsolatorio/GIST-Embedding-v0\n",
    "# intfloat/e5-large\n",
    "# uitnlp/visobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86810f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:23.377142Z",
     "iopub.status.busy": "2024-10-24T05:05:23.376851Z",
     "iopub.status.idle": "2024-10-24T05:05:23.380665Z",
     "shell.execute_reply": "2024-10-24T05:05:23.379843Z"
    },
    "papermill": {
     "duration": 0.08822,
     "end_time": "2024-10-24T05:05:23.382459",
     "exception": false,
     "start_time": "2024-10-24T05:05:23.294239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9879a216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:23.548149Z",
     "iopub.status.busy": "2024-10-24T05:05:23.547872Z",
     "iopub.status.idle": "2024-10-24T05:05:23.552048Z",
     "shell.execute_reply": "2024-10-24T05:05:23.551238Z"
    },
    "papermill": {
     "duration": 0.088895,
     "end_time": "2024-10-24T05:05:23.553917",
     "exception": false,
     "start_time": "2024-10-24T05:05:23.465022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=0 python TAS_BERT_joint.py \\\n",
    "# --data_dir /kaggle/working/HOSSemEval-EB23/TAS/data/VNModels_small/three_joint/BIO/ \\\n",
    "# --output_dir /kaggle/working/HOSSemEval-EB23/TAS/TAS-Transformers/results/VNModels_small/three_joint/BIO/my_result \\\n",
    "# --save_path /kaggle/working/HOSSemEval-EB23/TAS/TAS-Transformers/results/VNModels_small/three_joint/BIO/my_result \\\n",
    "# --model_name 'google/electra-large-discriminator' \\\n",
    "# --vocab_file /kaggle/working/HOSSemEval-EB23/TAS/TAS-Transformers/Vocab/vocab.txt \\\n",
    "# --tokenize_method word_split \\\n",
    "# --use_crf \\\n",
    "# --eval_test \\\n",
    "# --do_lower_case \\\n",
    "# --max_seq_length 128 \\\n",
    "# --train_batch_size 32 \\\n",
    "# --eval_batch_size 32 \\\n",
    "# --learning_rate 2e-5 \\\n",
    "# --num_train_epochs 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9234854c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:23.719866Z",
     "iopub.status.busy": "2024-10-24T05:05:23.719600Z",
     "iopub.status.idle": "2024-10-24T05:05:23.723373Z",
     "shell.execute_reply": "2024-10-24T05:05:23.722579Z"
    },
    "papermill": {
     "duration": 0.089675,
     "end_time": "2024-10-24T05:05:23.725762",
     "exception": false,
     "start_time": "2024-10-24T05:05:23.636087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python evaluation_for_TSD_ASD_TASD.py \\\n",
    "# --output_dir /kaggle/working/HOSSemEval-EB23/TAS/TAS-Transformers/results/VNModels_small/three_joint/BIO/my_result \\\n",
    "# --num_epochs 20 \\\n",
    "# --tag_schema BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c3efb4",
   "metadata": {
    "papermill": {
     "duration": 0.082079,
     "end_time": "2024-10-24T05:05:23.890686",
     "exception": false,
     "start_time": "2024-10-24T05:05:23.808607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **GAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa1743e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:24.056963Z",
     "iopub.status.busy": "2024-10-24T05:05:24.056678Z",
     "iopub.status.idle": "2024-10-24T05:05:24.060273Z",
     "shell.execute_reply": "2024-10-24T05:05:24.059446Z"
    },
    "papermill": {
     "duration": 0.089068,
     "end_time": "2024-10-24T05:05:24.062024",
     "exception": false,
     "start_time": "2024-10-24T05:05:23.972956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/HOSSemEval-EB23/GAS/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0188ab38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:24.234472Z",
     "iopub.status.busy": "2024-10-24T05:05:24.234101Z",
     "iopub.status.idle": "2024-10-24T05:05:24.238804Z",
     "shell.execute_reply": "2024-10-24T05:05:24.237807Z"
    },
    "papermill": {
     "duration": 0.09659,
     "end_time": "2024-10-24T05:05:24.240907",
     "exception": false,
     "start_time": "2024-10-24T05:05:24.144317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python main.py --task tasd \\\n",
    "#             --dataset hos_eb23 \\\n",
    "#             --model_name_or_path t5-base \\\n",
    "#             --paradigm extraction \\\n",
    "#             --n_gpu 0 \\\n",
    "#             --do_train \\\n",
    "#             --do_direct_eval \\\n",
    "#             --train_batch_size 16 \\\n",
    "#             --gradient_accumulation_steps 2 \\\n",
    "#             --eval_batch_size 16 \\\n",
    "#             --learning_rate 3e-4 \\\n",
    "#             --num_train_epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b64ae4d",
   "metadata": {
    "papermill": {
     "duration": 0.082216,
     "end_time": "2024-10-24T05:05:24.411219",
     "exception": false,
     "start_time": "2024-10-24T05:05:24.329003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **ASQP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e70a0721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:24.576622Z",
     "iopub.status.busy": "2024-10-24T05:05:24.576306Z",
     "iopub.status.idle": "2024-10-24T05:05:24.582599Z",
     "shell.execute_reply": "2024-10-24T05:05:24.581627Z"
    },
    "papermill": {
     "duration": 0.091199,
     "end_time": "2024-10-24T05:05:24.584442",
     "exception": false,
     "start_time": "2024-10-24T05:05:24.493243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/HOSSemEval-EB23/ASQP/T5\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/HOSSemEval-EB23/ASQP/T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e596000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:24.751149Z",
     "iopub.status.busy": "2024-10-24T05:05:24.750845Z",
     "iopub.status.idle": "2024-10-24T05:05:37.392230Z",
     "shell.execute_reply": "2024-10-24T05:05:37.391097Z"
    },
    "papermill": {
     "duration": 12.728212,
     "end_time": "2024-10-24T05:05:37.394693",
     "exception": false,
     "start_time": "2024-10-24T05:05:24.666481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.16.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.65.0)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.19.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.0)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.24.6)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.15.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2024.6.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.6.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.4)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.18.1)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\r\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers) (12.6.77)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2024.5.15)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.1.1)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.19.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2024.7.4)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (8.1.7)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d165d",
   "metadata": {
    "papermill": {
     "duration": 0.082897,
     "end_time": "2024-10-24T05:05:37.561961",
     "exception": false,
     "start_time": "2024-10-24T05:05:37.479064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- task refers to one of the ABSA task in [aope,uabsa,aste,tasd]. In our study, we run experiment on tasd.\n",
    "- dataset: hos_eb23 is used in our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abc861f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T05:05:37.729769Z",
     "iopub.status.busy": "2024-10-24T05:05:37.729404Z",
     "iopub.status.idle": "2024-10-24T05:07:37.371228Z",
     "shell.execute_reply": "2024-10-24T05:07:37.369978Z"
    },
    "papermill": {
     "duration": 119.728359,
     "end_time": "2024-10-24T05:07:37.373674",
     "exception": false,
     "start_time": "2024-10-24T05:05:37.645315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " ============================== NEW EXP: ASQP on hotel_en ============================== \r\n",
      "\r\n",
      "Downloading: 100%|███████████████████████████| 773k/773k [00:00<00:00, 6.25MB/s]\r\n",
      "Downloading: 100%|█████████████████████████| 1.32M/1.32M [00:00<00:00, 18.9MB/s]\r\n",
      "Downloading: 100%|█████████████████████████| 1.18k/1.18k [00:00<00:00, 6.15MB/s]\r\n",
      "Here is an example (from the dev set):\r\n",
      "Input : The quality of the room is too old, the interior is poor.\r\n",
      "Output: facility is bad because the quality of the room is too old, the interior is poor is bad\r\n",
      "\r\n",
      "****** Conduct Training ******\r\n",
      "Downloading: 100%|█████████████████████████| 2.75G/2.75G [00:54<00:00, 54.1MB/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\r\n",
      "  warnings.warn(\r\n",
      "Sanity Checking: 0it [00:00, ?it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\r\n",
      "  self.pid = os.fork()\r\n",
      "Epoch 0:   0%|                                          | 0/772 [00:00<?, ?it/s]Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/HOSSemEval-EB23/ASQP/T5/main.py\", line 428, in <module>\r\n",
      "    trainer.fit(model)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 608, in fit\r\n",
      "    call._call_and_handle_interrupt(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\r\n",
      "    return trainer_fn(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _fit_impl\r\n",
      "    self._run(model, ckpt_path=self.ckpt_path)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1112, in _run\r\n",
      "    results = self._run_stage()\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1191, in _run_stage\r\n",
      "    self._run_train()\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1214, in _run_train\r\n",
      "    self.fit_loop.run()\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\r\n",
      "    self.advance(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 267, in advance\r\n",
      "    self._outputs = self.epoch_loop.run(self._data_fetcher)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\r\n",
      "    self.advance(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 213, in advance\r\n",
      "    batch_output = self.batch_loop.run(kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\r\n",
      "    self.advance(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 88, in advance\r\n",
      "    outputs = self.optimizer_loop.run(optimizers, kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\r\n",
      "    self.advance(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 202, in advance\r\n",
      "    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 249, in _run_optimization\r\n",
      "    self._optimizer_step(optimizer, opt_idx, kwargs.get(\"batch_idx\", 0), closure)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 370, in _optimizer_step\r\n",
      "    self.trainer._call_lightning_module_hook(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1356, in _call_lightning_module_hook\r\n",
      "    output = fn(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/module.py\", line 1754, in optimizer_step\r\n",
      "    optimizer.step(closure=optimizer_closure)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py\", line 169, in step\r\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 234, in optimizer_step\r\n",
      "    return self.precision_plugin.optimizer_step(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 119, in optimizer_step\r\n",
      "    return optimizer.step(closure=closure, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\r\n",
      "    return wrapped(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 373, in wrapper\r\n",
      "    out = func(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py\", line 332, in step\r\n",
      "    loss = closure()\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 105, in _wrap_closure\r\n",
      "    closure_result = closure()\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 149, in __call__\r\n",
      "    self._result = self.closure(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 135, in closure\r\n",
      "    step_output = self._step_fn()\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 419, in _training_step\r\n",
      "    training_step_output = self.trainer._call_strategy_hook(\"training_step\", *kwargs.values())\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1494, in _call_strategy_hook\r\n",
      "    output = fn(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 378, in training_step\r\n",
      "    return self.model.training_step(*args, **kwargs)\r\n",
      "  File \"/kaggle/working/HOSSemEval-EB23/ASQP/T5/main.py\", line 173, in training_step\r\n",
      "    loss = self._step(batch)\r\n",
      "  File \"/kaggle/working/HOSSemEval-EB23/ASQP/T5/main.py\", line 162, in _step\r\n",
      "    outputs = self(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/kaggle/working/HOSSemEval-EB23/ASQP/T5/main.py\", line 150, in forward\r\n",
      "    return self.model(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 1616, in forward\r\n",
      "    decoder_outputs = self.decoder(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 1011, in forward\r\n",
      "    layer_outputs = layer_module(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 646, in forward\r\n",
      "    self_attention_outputs = self.layer[0](\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 553, in forward\r\n",
      "    attention_output = self.SelfAttention(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 513, in forward\r\n",
      "    attn_weights = nn.functional.softmax(scores.float(), dim=-1).type_as(\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py\", line 1856, in softmax\r\n",
      "    ret = input.softmax(dim)\r\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 23.12 MiB is free. Process 4663 has 15.86 GiB memory in use. Of the allocated memory 14.81 GiB is allocated by PyTorch, and 785.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\n"
     ]
    }
   ],
   "source": [
    "!python main.py --task tasd \\\n",
    "            --dataset hotel_en \\\n",
    "            --model_name_or_path t5-large \\\n",
    "            --n_gpu 0 \\\n",
    "            --do_train \\\n",
    "            --do_direct_eval \\\n",
    "            --train_batch_size 16 \\\n",
    "            --gradient_accumulation_steps 1 \\\n",
    "            --eval_batch_size 16 \\\n",
    "            --learning_rate 3e-4 \\\n",
    "            --num_train_epochs 30"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 314.543072,
   "end_time": "2024-10-24T05:07:37.720648",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-24T05:02:23.177576",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
